# -*- coding: utf-8 -*-
"""Fraud Transaction Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PWEyLMm9vmVLRamjBuYp10OQQTJzAZv-
"""

from google.colab import files
uploaded = files.upload()  # Upload your `data.zip`

import zipfile
import os

with zipfile.ZipFile("data.zip", "r") as zip_ref:
    zip_ref.extractall("data")

import pandas as pd
import os

# Path to unzipped folder
folder_path = "data/data"

# Read all .pkl files into a single dataframe
df_list = []

for filename in os.listdir(folder_path):
    if filename.endswith('.pkl'):
        file_path = os.path.join(folder_path, filename)
        df = pd.read_pickle(file_path)
        df_list.append(df)

# Combine all dataframes
data = pd.concat(df_list, ignore_index=True)
print(data.head())

print(data.info())
print(data.describe())
print(data['TX_FRAUD'].value_counts())  # Check fraud vs non-fraud

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Encode datetime
data['TX_DATETIME'] = pd.to_datetime(data['TX_DATETIME'])
data['HOUR'] = data['TX_DATETIME'].dt.hour
data['DAY'] = data['TX_DATETIME'].dt.day

# Drop unused columns or encode as needed
X = data.drop(columns=['TX_FRAUD', 'TX_DATETIME', 'TRANSACTION_ID'])
y = data['TX_FRAUD']

# Encode categorical columns if any
le = LabelEncoder()
X['CUSTOMER_ID'] = le.fit_transform(X['CUSTOMER_ID'])
X['TERMINAL_ID'] = le.fit_transform(X['TERMINAL_ID'])

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

model = RandomForestClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

# AUC-ROC Score
print("AUC Score:", roc_auc_score(y_test, y_pred))

import joblib

# Save model
joblib.dump(model, 'fraud_model.pkl')

# Save label encoders (if you used any)
joblib.dump(le, 'customer_encoder.pkl')

model = joblib.load('fraud_model.pkl')
le = joblib.load('customer_encoder.pkl')

# Fraud distribution
sns.countplot(data['TX_FRAUD'])
plt.title("Fraud vs Non-Fraud Distribution")
plt.show()

# Fraud by hour
data.groupby('HOUR')['TX_FRAUD'].mean().plot(kind='bar')
plt.title("Fraud Rate by Hour")
plt.ylabel("Fraud Rate")
plt.show()