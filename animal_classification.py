# -*- coding: utf-8 -*-
"""Animal classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K1MVWCkrnte1jxl-tkS11TzXvv9rj5A4
"""

from google.colab import files

# Upload animals.zip from your computer
uploaded = files.upload()

import zipfile

# Unzip the uploaded file into /content/animals
with zipfile.ZipFile('animals.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/animals')

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

base_dir = '/animals'

# ImageDataGenerator helps load and prepare images for the model
image_gen = ImageDataGenerator(
    rescale=1./255,      # Scale pixel values from 0-255 to 0-1
    validation_split=0.2 # 20% of images used for validation
)

train_data = image_gen.flow_from_directory(
    base_dir,
    target_size=(224, 224),
    batch_size=32,
    subset='training',
    class_mode='categorical'
)

val_data = image_gen.flow_from_directory(
    base_dir,
    target_size=(224, 224),
    batch_size=32,
    subset='validation',
    class_mode='categorical'
)

# Get the actual number of classes from the training data generator
num_classes = train_data.num_classes

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Freeze it so it doesn't retrain

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
# Update the final Dense layer to use the detected number of classes
predictions = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# Recompile the model after changing the architecture
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Now the fit method should work
history = model.fit(train_data, epochs=10, validation_data=val_data)

import matplotlib.pyplot as plt

# Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title("Accuracy over epochs")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.show()

# Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title("Loss over epochs")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

model.evaluate(val_data)

from google.colab import files
from tensorflow.keras.preprocessing import image
import numpy as np
import os

# Step 1: Upload an image (JPG or JPEG)
uploaded = files.upload()  # Youâ€™ll upload one image here

# Step 2: Get the uploaded file name automatically
filename = next(iter(uploaded))  # Gets the first uploaded file name

# Step 3: Load and preprocess the image
img = image.load_img(filename, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array = img_array / 255.0  # Normalize the image

# Step 4: Predict using the trained model
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions)

# Step 5: Get class labels from the training data
class_labels = list(train_data.class_indices.keys())
print("Predicted Animal:", class_labels[predicted_class])